# Industrial Mix Generation Pipeline

This document explains the industrial mix generator built around `scripts/generate_industrial_mix.sh`, which creates multiple industrial stems and stitches them into a continuous mix.

## Concept

We want a self-contained script that:

1. Builds a Docker image with Audiocraft/MusicGen.
2. Generates multiple small-model industrial ambience tracks.
3. Generates multiple medium-model industrial transition tracks.
4. Concatenates all tracks into a single long industrial mix using ffmpeg.

The result is a DJ-style continuous industrial set that can be used for background music, game ambience, or inspiration for further production.

## Script Overview

The orchestrator script is `scripts/generate_industrial_mix.sh`.

High-level steps:

1. **Build image** `audiocraft:large.community` from `docker/Dockerfile.large.community`.
2. **Prepare output dirs** inside `workspace/` for small and medium stems.
3. **Generate 5 small-model stems** (60 seconds each) using `musicgen-small`.
4. **Generate 3 medium-model stems** (30 seconds each) using `musicgen-medium`.
5. **Create a concat list file** that defines the order of clips.
6. **Run ffmpeg inside Docker** to stitch the stems into `workspace/industrial_mix_full.wav`.

## Style Definitions

The musical style is defined in `workspace/industrial_styles.py` with two constants:

- `SMALL_INDUSTRIAL_STYLE`: a long, detailed description of a 60-second industrial house / EBM track.
- `MEDIUM_INDUSTRIAL_STYLE`: a description of a 30-second high-intensity industrial EDM transition.

The shell script invokes Python inside the container to import and print these strings, which become the `--prompt` text for MusicGen.

This indirection allows experimenting with styles without editing the shell script.

Note on models: the orchestration supports selecting local or HF models via `workspace/models_manifest.json` and `workspace/hf_generate.py` (`--model-key`), so you can swap `musicgen-medium` for `musicgen-style` without changing the shell script when the manifest/cache is populated.

## Generation Details

Small stems:

- Model: `musicgen-small`.
- Duration: 60 seconds.
- Count: 5 stems.
- Purpose: provide longer background sections and recurring motifs.

Medium stems:

- Model: `musicgen-medium`.
- Duration: 30 seconds.
- Count: 3 stems.
- Purpose: provide intense transitions and drops between the longer small stems.

The approximate total length of the final mix with current settings is:

- 5 × 60s = 300 seconds.
- 3 × 30s = 90 seconds.
- Total ≈ 390 seconds ≈ 6.5 minutes.

## Ordering and Stitching

The file `workspace/output_industrial_concat_list.txt` is auto-generated by the script. It currently defines this order:

1. `industrial_small_1.wav`
2. `industrial_medium_1.wav`
3. `industrial_small_2.wav`
4. `industrial_medium_2.wav`
5. `industrial_small_3.wav`
6. `industrial_medium_3.wav`
7. `industrial_small_4.wav`
8. `industrial_small_5.wav`

ffmpeg then concatenates these in sequence:

```bash
ffmpeg -y -f concat -safe 0 -i output_industrial_concat_list.txt -c copy industrial_mix_full.wav
```

All stems must share the same sample rate and channel configuration (which they do when generated by the same MusicGen stack).

## Logs and Debugging

Each generation is logged under `workspace/tests/logs/` as `industrial_small_i.log` and `industrial_medium_i.log`. These logs capture:

- The exact prompt used.
- Any runtime warnings or CUDA memory issues.

If a generation fails (e.g. out of memory), the script will exit with an error and you can inspect the corresponding log file.

## Customization Ideas

- Change the **number of stems** to alter mix length.
- Modify the **concat order** to change narrative flow.
- Swap in different styles in `industrial_styles.py` (e.g. more techno, more ambient, more noise).
- Generate multiple mixes with different seeds and compare results.

This pipeline is a foundation for fully automated industrial sets built from AI-generated stems.
